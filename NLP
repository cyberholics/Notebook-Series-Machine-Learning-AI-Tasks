{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2664123,"sourceType":"datasetVersion","datasetId":1611656}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/victorkingoshimua/ml-paper-recommender?scriptVersionId=182477261\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/pat_timeython Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_colwidth', None)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T03:29:51.553916Z","iopub.execute_input":"2024-06-10T03:29:51.555022Z","iopub.status.idle":"2024-06-10T03:29:51.564121Z","shell.execute_reply.started":"2024-06-10T03:29:51.554982Z","shell.execute_reply":"2024-06-10T03:29:51.563042Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"/kaggle/input/arxiv-paper-abstracts/arxiv_data_210930-054931.csv\n/kaggle/input/arxiv-paper-abstracts/arxiv_data.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Introduction\nFinding relevant ML research papers to read based on your interests can be a stressful task. What if you could just prompt an app with your interests to recommend a paper for you?\n\nIn this notebook, we will build an ML app that can recommend research papers for you based on your interests.\nThis is an NLP task","metadata":{}},{"cell_type":"code","source":"## Read and load the training data\ndata = pd.read_csv(\"/kaggle/input/arxiv-paper-abstracts/arxiv_data.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-10T03:29:51.571206Z","iopub.execute_input":"2024-06-10T03:29:51.57164Z","iopub.status.idle":"2024-06-10T03:29:52.299146Z","shell.execute_reply.started":"2024-06-10T03:29:51.571597Z","shell.execute_reply":"2024-06-10T03:29:52.297812Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"                                                                                                                          titles  \\\n0                                                                 Survey on Semantic Stereo Matching / Semantic Depth Estimation   \n1  FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging   \n2                                    Enforcing Mutual Consistency of Hard Regions for Semi-supervised Medical Image Segmentation   \n3                                                  Parameter Decoupling Strategy for Semi-supervised 3D Left Atrium Segmentation   \n4                                                 Background-Foreground Segmentation for Interior Sensing in Automotive Industry   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             summaries  \\\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Stereo matching is one of the widely used techniques for inferring depth from\\nstereo images owing to its robustness and speed. It has become one of the major\\ntopics of research since it finds its applications in autonomous driving,\\nrobotic navigation, 3D reconstruction, and many other fields. Finding pixel\\ncorrespondences in non-textured, occluded and reflective areas is the major\\nchallenge in stereo matching. Recent developments have shown that semantic cues\\nfrom image segmentation can be used to improve the results of stereo matching.\\nMany deep neural network architectures have been proposed to leverage the\\nadvantages of semantic segmentation in stereo matching. This paper aims to give\\na comparison among the state of art networks both in terms of accuracy and in\\nterms of speed which are of higher importance in real-time applications.   \n1                                                                                                                                                                                                                                                                                                                                      The recent advancements in artificial intelligence (AI) combined with the\\nextensive amount of data generated by today's clinical systems, has led to the\\ndevelopment of imaging AI solutions across the whole value chain of medical\\nimaging, including image reconstruction, medical image segmentation,\\nimage-based diagnosis and treatment planning. Notwithstanding the successes and\\nfuture potential of AI in medical imaging, many stakeholders are concerned of\\nthe potential risks and ethical implications of imaging AI solutions, which are\\nperceived as complex, opaque, and difficult to comprehend, utilise, and trust\\nin critical clinical applications. Despite these concerns and risks, there are\\ncurrently no concrete guidelines and best practices for guiding future AI\\ndevelopments in medical imaging towards increased trust, safety and adoption.\\nTo bridge this gap, this paper introduces a careful selection of guiding\\nprinciples drawn from the accumulated experiences, consensus, and best\\npractices from five large European projects on AI in Health Imaging. These\\nguiding principles are named FUTURE-AI and its building blocks consist of (i)\\nFairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness\\nand (vi) Explainability. In a step-by-step approach, these guidelines are\\nfurther translated into a framework of concrete recommendations for specifying,\\ndeveloping, evaluating, and deploying technically, clinically and ethically\\ntrustworthy AI solutions into clinical practice.   \n2                                                                                                                                                                                   In this paper, we proposed a novel mutual consistency network (MC-Net+) to\\neffectively exploit the unlabeled hard regions for semi-supervised medical\\nimage segmentation. The MC-Net+ model is motivated by the observation that deep\\nmodels trained with limited annotations are prone to output highly uncertain\\nand easily mis-classified predictions in the ambiguous regions (e.g. adhesive\\nedges or thin branches) for the image segmentation task. Leveraging these\\nregion-level challenging samples can make the semi-supervised segmentation\\nmodel training more effective. Therefore, our proposed MC-Net+ model consists\\nof two new designs. First, the model contains one shared encoder and multiple\\nsightly different decoders (i.e. using different up-sampling strategies). The\\nstatistical discrepancy of multiple decoders' outputs is computed to denote the\\nmodel's uncertainty, which indicates the unlabeled hard regions. Second, a new\\nmutual consistency constraint is enforced between one decoder's probability\\noutput and other decoders' soft pseudo labels. In this way, we minimize the\\nmodel's uncertainty during training and force the model to generate invariant\\nand low-entropy results in such challenging areas of unlabeled data, in order\\nto learn a generalized feature representation. We compared the segmentation\\nresults of the MC-Net+ with five state-of-the-art semi-supervised approaches on\\nthree public medical datasets. Extension experiments with two common\\nsemi-supervised settings demonstrate the superior performance of our model over\\nother existing methods, which sets a new state of the art for semi-supervised\\nmedical image segmentation.   \n3                                                                                                                                                                                                                                                                                                                                                                                Consistency training has proven to be an advanced semi-supervised framework\\nand achieved promising results in medical image segmentation tasks through\\nenforcing an invariance of the predictions over different views of the inputs.\\nHowever, with the iterative updating of model parameters, the models would tend\\nto reach a coupled state and eventually lose the ability to exploit unlabeled\\ndata. To address the issue, we present a novel semi-supervised segmentation\\nmodel based on parameter decoupling strategy to encourage consistent\\npredictions from diverse views. Specifically, we first adopt a two-branch\\nnetwork to simultaneously produce predictions for each image. During the\\ntraining process, we decouple the two prediction branch parameters by quadratic\\ncosine distance to construct different views in latent space. Based on this,\\nthe feature extractor is constrained to encourage the consistency of\\nprobability maps generated by classifiers under diversified features. In the\\noverall training process, the parameters of feature extractor and classifiers\\nare updated alternately by consistency regularization operation and decoupling\\noperation to gradually improve the generalization performance of the model. Our\\nmethod has achieved a competitive result over the state-of-the-art\\nsemi-supervised methods on the Atrial Segmentation Challenge dataset,\\ndemonstrating the effectiveness of our framework. Code is available at\\nhttps://github.com/BX0903/PDC.   \n4  To ensure safety in automated driving, the correct perception of the\\nsituation inside the car is as important as its environment. Thus, seat\\noccupancy detection and classification of detected instances play an important\\nrole in interior sensing. By the knowledge of the seat occupancy status, it is\\npossible to, e.g., automate the airbag deployment control. Furthermore, the\\npresence of a driver, which is necessary for partially automated driving cars\\nat the automation levels two to four can be verified. In this work, we compare\\ndifferent statistical methods from the field of image segmentation to approach\\nthe problem of background-foreground segmentation in camera based interior\\nsensing. In the recent years, several methods based on different techniques\\nhave been developed and applied to images or videos from different\\napplications. The peculiarity of the given scenarios of interior sensing is,\\nthat the foreground instances and the background both contain static as well as\\ndynamic elements. In data considered in this work, even the camera position is\\nnot completely fixed. We review and benchmark three different methods ranging,\\ni.e., Gaussian Mixture Models (GMM), Morphological Snakes and a deep neural\\nnetwork, namely a Mask R-CNN. In particular, the limitations of the classical\\nmethods, GMM and Morphological Snakes, for interior sensing are shown.\\nFurthermore, it turns, that it is possible to overcome these limitations by\\ndeep learning, e.g.\\ using a Mask R-CNN. Although only a small amount of ground\\ntruth data was available for training, we enabled the Mask R-CNN to produce\\nhigh quality background-foreground masks via transfer learning. Moreover, we\\ndemonstrate that certain augmentation as well as pre- and post-processing\\nmethods further enhance the performance of the investigated methods.   \n\n                         terms  \n0           ['cs.CV', 'cs.LG']  \n1  ['cs.CV', 'cs.AI', 'cs.LG']  \n2           ['cs.CV', 'cs.AI']  \n3                    ['cs.CV']  \n4           ['cs.CV', 'cs.LG']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>titles</th>\n      <th>summaries</th>\n      <th>terms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Survey on Semantic Stereo Matching / Semantic Depth Estimation</td>\n      <td>Stereo matching is one of the widely used techniques for inferring depth from\\nstereo images owing to its robustness and speed. It has become one of the major\\ntopics of research since it finds its applications in autonomous driving,\\nrobotic navigation, 3D reconstruction, and many other fields. Finding pixel\\ncorrespondences in non-textured, occluded and reflective areas is the major\\nchallenge in stereo matching. Recent developments have shown that semantic cues\\nfrom image segmentation can be used to improve the results of stereo matching.\\nMany deep neural network architectures have been proposed to leverage the\\nadvantages of semantic segmentation in stereo matching. This paper aims to give\\na comparison among the state of art networks both in terms of accuracy and in\\nterms of speed which are of higher importance in real-time applications.</td>\n      <td>['cs.CV', 'cs.LG']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging</td>\n      <td>The recent advancements in artificial intelligence (AI) combined with the\\nextensive amount of data generated by today's clinical systems, has led to the\\ndevelopment of imaging AI solutions across the whole value chain of medical\\nimaging, including image reconstruction, medical image segmentation,\\nimage-based diagnosis and treatment planning. Notwithstanding the successes and\\nfuture potential of AI in medical imaging, many stakeholders are concerned of\\nthe potential risks and ethical implications of imaging AI solutions, which are\\nperceived as complex, opaque, and difficult to comprehend, utilise, and trust\\nin critical clinical applications. Despite these concerns and risks, there are\\ncurrently no concrete guidelines and best practices for guiding future AI\\ndevelopments in medical imaging towards increased trust, safety and adoption.\\nTo bridge this gap, this paper introduces a careful selection of guiding\\nprinciples drawn from the accumulated experiences, consensus, and best\\npractices from five large European projects on AI in Health Imaging. These\\nguiding principles are named FUTURE-AI and its building blocks consist of (i)\\nFairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness\\nand (vi) Explainability. In a step-by-step approach, these guidelines are\\nfurther translated into a framework of concrete recommendations for specifying,\\ndeveloping, evaluating, and deploying technically, clinically and ethically\\ntrustworthy AI solutions into clinical practice.</td>\n      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Enforcing Mutual Consistency of Hard Regions for Semi-supervised Medical Image Segmentation</td>\n      <td>In this paper, we proposed a novel mutual consistency network (MC-Net+) to\\neffectively exploit the unlabeled hard regions for semi-supervised medical\\nimage segmentation. The MC-Net+ model is motivated by the observation that deep\\nmodels trained with limited annotations are prone to output highly uncertain\\nand easily mis-classified predictions in the ambiguous regions (e.g. adhesive\\nedges or thin branches) for the image segmentation task. Leveraging these\\nregion-level challenging samples can make the semi-supervised segmentation\\nmodel training more effective. Therefore, our proposed MC-Net+ model consists\\nof two new designs. First, the model contains one shared encoder and multiple\\nsightly different decoders (i.e. using different up-sampling strategies). The\\nstatistical discrepancy of multiple decoders' outputs is computed to denote the\\nmodel's uncertainty, which indicates the unlabeled hard regions. Second, a new\\nmutual consistency constraint is enforced between one decoder's probability\\noutput and other decoders' soft pseudo labels. In this way, we minimize the\\nmodel's uncertainty during training and force the model to generate invariant\\nand low-entropy results in such challenging areas of unlabeled data, in order\\nto learn a generalized feature representation. We compared the segmentation\\nresults of the MC-Net+ with five state-of-the-art semi-supervised approaches on\\nthree public medical datasets. Extension experiments with two common\\nsemi-supervised settings demonstrate the superior performance of our model over\\nother existing methods, which sets a new state of the art for semi-supervised\\nmedical image segmentation.</td>\n      <td>['cs.CV', 'cs.AI']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Parameter Decoupling Strategy for Semi-supervised 3D Left Atrium Segmentation</td>\n      <td>Consistency training has proven to be an advanced semi-supervised framework\\nand achieved promising results in medical image segmentation tasks through\\nenforcing an invariance of the predictions over different views of the inputs.\\nHowever, with the iterative updating of model parameters, the models would tend\\nto reach a coupled state and eventually lose the ability to exploit unlabeled\\ndata. To address the issue, we present a novel semi-supervised segmentation\\nmodel based on parameter decoupling strategy to encourage consistent\\npredictions from diverse views. Specifically, we first adopt a two-branch\\nnetwork to simultaneously produce predictions for each image. During the\\ntraining process, we decouple the two prediction branch parameters by quadratic\\ncosine distance to construct different views in latent space. Based on this,\\nthe feature extractor is constrained to encourage the consistency of\\nprobability maps generated by classifiers under diversified features. In the\\noverall training process, the parameters of feature extractor and classifiers\\nare updated alternately by consistency regularization operation and decoupling\\noperation to gradually improve the generalization performance of the model. Our\\nmethod has achieved a competitive result over the state-of-the-art\\nsemi-supervised methods on the Atrial Segmentation Challenge dataset,\\ndemonstrating the effectiveness of our framework. Code is available at\\nhttps://github.com/BX0903/PDC.</td>\n      <td>['cs.CV']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Background-Foreground Segmentation for Interior Sensing in Automotive Industry</td>\n      <td>To ensure safety in automated driving, the correct perception of the\\nsituation inside the car is as important as its environment. Thus, seat\\noccupancy detection and classification of detected instances play an important\\nrole in interior sensing. By the knowledge of the seat occupancy status, it is\\npossible to, e.g., automate the airbag deployment control. Furthermore, the\\npresence of a driver, which is necessary for partially automated driving cars\\nat the automation levels two to four can be verified. In this work, we compare\\ndifferent statistical methods from the field of image segmentation to approach\\nthe problem of background-foreground segmentation in camera based interior\\nsensing. In the recent years, several methods based on different techniques\\nhave been developed and applied to images or videos from different\\napplications. The peculiarity of the given scenarios of interior sensing is,\\nthat the foreground instances and the background both contain static as well as\\ndynamic elements. In data considered in this work, even the camera position is\\nnot completely fixed. We review and benchmark three different methods ranging,\\ni.e., Gaussian Mixture Models (GMM), Morphological Snakes and a deep neural\\nnetwork, namely a Mask R-CNN. In particular, the limitations of the classical\\nmethods, GMM and Morphological Snakes, for interior sensing are shown.\\nFurthermore, it turns, that it is possible to overcome these limitations by\\ndeep learning, e.g.\\ using a Mask R-CNN. Although only a small amount of ground\\ntruth data was available for training, we enabled the Mask R-CNN to produce\\nhigh quality background-foreground masks via transfer learning. Moreover, we\\ndemonstrate that certain augmentation as well as pre- and post-processing\\nmethods further enhance the performance of the investigated methods.</td>\n      <td>['cs.CV', 'cs.LG']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The `terms` columns might not be relivant for this task. It is safe to drop it.","metadata":{}},{"cell_type":"code","source":"data =  data[[\"titles\",\"summaries\"]]","metadata":{"execution":{"iopub.status.busy":"2024-06-10T03:29:52.301142Z","iopub.execute_input":"2024-06-10T03:29:52.301518Z","iopub.status.idle":"2024-06-10T03:29:52.310383Z","shell.execute_reply.started":"2024-06-10T03:29:52.301487Z","shell.execute_reply":"2024-06-10T03:29:52.309064Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-10T03:29:52.311843Z","iopub.execute_input":"2024-06-10T03:29:52.312234Z","iopub.status.idle":"2024-06-10T03:29:52.328193Z","shell.execute_reply.started":"2024-06-10T03:29:52.312203Z","shell.execute_reply":"2024-06-10T03:29:52.326761Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"                                                                                                                          titles  \\\n0                                                                 Survey on Semantic Stereo Matching / Semantic Depth Estimation   \n1  FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging   \n2                                    Enforcing Mutual Consistency of Hard Regions for Semi-supervised Medical Image Segmentation   \n3                                                  Parameter Decoupling Strategy for Semi-supervised 3D Left Atrium Segmentation   \n4                                                 Background-Foreground Segmentation for Interior Sensing in Automotive Industry   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             summaries  \n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Stereo matching is one of the widely used techniques for inferring depth from\\nstereo images owing to its robustness and speed. It has become one of the major\\ntopics of research since it finds its applications in autonomous driving,\\nrobotic navigation, 3D reconstruction, and many other fields. Finding pixel\\ncorrespondences in non-textured, occluded and reflective areas is the major\\nchallenge in stereo matching. Recent developments have shown that semantic cues\\nfrom image segmentation can be used to improve the results of stereo matching.\\nMany deep neural network architectures have been proposed to leverage the\\nadvantages of semantic segmentation in stereo matching. This paper aims to give\\na comparison among the state of art networks both in terms of accuracy and in\\nterms of speed which are of higher importance in real-time applications.  \n1                                                                                                                                                                                                                                                                                                                                      The recent advancements in artificial intelligence (AI) combined with the\\nextensive amount of data generated by today's clinical systems, has led to the\\ndevelopment of imaging AI solutions across the whole value chain of medical\\nimaging, including image reconstruction, medical image segmentation,\\nimage-based diagnosis and treatment planning. Notwithstanding the successes and\\nfuture potential of AI in medical imaging, many stakeholders are concerned of\\nthe potential risks and ethical implications of imaging AI solutions, which are\\nperceived as complex, opaque, and difficult to comprehend, utilise, and trust\\nin critical clinical applications. Despite these concerns and risks, there are\\ncurrently no concrete guidelines and best practices for guiding future AI\\ndevelopments in medical imaging towards increased trust, safety and adoption.\\nTo bridge this gap, this paper introduces a careful selection of guiding\\nprinciples drawn from the accumulated experiences, consensus, and best\\npractices from five large European projects on AI in Health Imaging. These\\nguiding principles are named FUTURE-AI and its building blocks consist of (i)\\nFairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness\\nand (vi) Explainability. In a step-by-step approach, these guidelines are\\nfurther translated into a framework of concrete recommendations for specifying,\\ndeveloping, evaluating, and deploying technically, clinically and ethically\\ntrustworthy AI solutions into clinical practice.  \n2                                                                                                                                                                                   In this paper, we proposed a novel mutual consistency network (MC-Net+) to\\neffectively exploit the unlabeled hard regions for semi-supervised medical\\nimage segmentation. The MC-Net+ model is motivated by the observation that deep\\nmodels trained with limited annotations are prone to output highly uncertain\\nand easily mis-classified predictions in the ambiguous regions (e.g. adhesive\\nedges or thin branches) for the image segmentation task. Leveraging these\\nregion-level challenging samples can make the semi-supervised segmentation\\nmodel training more effective. Therefore, our proposed MC-Net+ model consists\\nof two new designs. First, the model contains one shared encoder and multiple\\nsightly different decoders (i.e. using different up-sampling strategies). The\\nstatistical discrepancy of multiple decoders' outputs is computed to denote the\\nmodel's uncertainty, which indicates the unlabeled hard regions. Second, a new\\nmutual consistency constraint is enforced between one decoder's probability\\noutput and other decoders' soft pseudo labels. In this way, we minimize the\\nmodel's uncertainty during training and force the model to generate invariant\\nand low-entropy results in such challenging areas of unlabeled data, in order\\nto learn a generalized feature representation. We compared the segmentation\\nresults of the MC-Net+ with five state-of-the-art semi-supervised approaches on\\nthree public medical datasets. Extension experiments with two common\\nsemi-supervised settings demonstrate the superior performance of our model over\\nother existing methods, which sets a new state of the art for semi-supervised\\nmedical image segmentation.  \n3                                                                                                                                                                                                                                                                                                                                                                                Consistency training has proven to be an advanced semi-supervised framework\\nand achieved promising results in medical image segmentation tasks through\\nenforcing an invariance of the predictions over different views of the inputs.\\nHowever, with the iterative updating of model parameters, the models would tend\\nto reach a coupled state and eventually lose the ability to exploit unlabeled\\ndata. To address the issue, we present a novel semi-supervised segmentation\\nmodel based on parameter decoupling strategy to encourage consistent\\npredictions from diverse views. Specifically, we first adopt a two-branch\\nnetwork to simultaneously produce predictions for each image. During the\\ntraining process, we decouple the two prediction branch parameters by quadratic\\ncosine distance to construct different views in latent space. Based on this,\\nthe feature extractor is constrained to encourage the consistency of\\nprobability maps generated by classifiers under diversified features. In the\\noverall training process, the parameters of feature extractor and classifiers\\nare updated alternately by consistency regularization operation and decoupling\\noperation to gradually improve the generalization performance of the model. Our\\nmethod has achieved a competitive result over the state-of-the-art\\nsemi-supervised methods on the Atrial Segmentation Challenge dataset,\\ndemonstrating the effectiveness of our framework. Code is available at\\nhttps://github.com/BX0903/PDC.  \n4  To ensure safety in automated driving, the correct perception of the\\nsituation inside the car is as important as its environment. Thus, seat\\noccupancy detection and classification of detected instances play an important\\nrole in interior sensing. By the knowledge of the seat occupancy status, it is\\npossible to, e.g., automate the airbag deployment control. Furthermore, the\\npresence of a driver, which is necessary for partially automated driving cars\\nat the automation levels two to four can be verified. In this work, we compare\\ndifferent statistical methods from the field of image segmentation to approach\\nthe problem of background-foreground segmentation in camera based interior\\nsensing. In the recent years, several methods based on different techniques\\nhave been developed and applied to images or videos from different\\napplications. The peculiarity of the given scenarios of interior sensing is,\\nthat the foreground instances and the background both contain static as well as\\ndynamic elements. In data considered in this work, even the camera position is\\nnot completely fixed. We review and benchmark three different methods ranging,\\ni.e., Gaussian Mixture Models (GMM), Morphological Snakes and a deep neural\\nnetwork, namely a Mask R-CNN. In particular, the limitations of the classical\\nmethods, GMM and Morphological Snakes, for interior sensing are shown.\\nFurthermore, it turns, that it is possible to overcome these limitations by\\ndeep learning, e.g.\\ using a Mask R-CNN. Although only a small amount of ground\\ntruth data was available for training, we enabled the Mask R-CNN to produce\\nhigh quality background-foreground masks via transfer learning. Moreover, we\\ndemonstrate that certain augmentation as well as pre- and post-processing\\nmethods further enhance the performance of the investigated methods.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>titles</th>\n      <th>summaries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Survey on Semantic Stereo Matching / Semantic Depth Estimation</td>\n      <td>Stereo matching is one of the widely used techniques for inferring depth from\\nstereo images owing to its robustness and speed. It has become one of the major\\ntopics of research since it finds its applications in autonomous driving,\\nrobotic navigation, 3D reconstruction, and many other fields. Finding pixel\\ncorrespondences in non-textured, occluded and reflective areas is the major\\nchallenge in stereo matching. Recent developments have shown that semantic cues\\nfrom image segmentation can be used to improve the results of stereo matching.\\nMany deep neural network architectures have been proposed to leverage the\\nadvantages of semantic segmentation in stereo matching. This paper aims to give\\na comparison among the state of art networks both in terms of accuracy and in\\nterms of speed which are of higher importance in real-time applications.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging</td>\n      <td>The recent advancements in artificial intelligence (AI) combined with the\\nextensive amount of data generated by today's clinical systems, has led to the\\ndevelopment of imaging AI solutions across the whole value chain of medical\\nimaging, including image reconstruction, medical image segmentation,\\nimage-based diagnosis and treatment planning. Notwithstanding the successes and\\nfuture potential of AI in medical imaging, many stakeholders are concerned of\\nthe potential risks and ethical implications of imaging AI solutions, which are\\nperceived as complex, opaque, and difficult to comprehend, utilise, and trust\\nin critical clinical applications. Despite these concerns and risks, there are\\ncurrently no concrete guidelines and best practices for guiding future AI\\ndevelopments in medical imaging towards increased trust, safety and adoption.\\nTo bridge this gap, this paper introduces a careful selection of guiding\\nprinciples drawn from the accumulated experiences, consensus, and best\\npractices from five large European projects on AI in Health Imaging. These\\nguiding principles are named FUTURE-AI and its building blocks consist of (i)\\nFairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness\\nand (vi) Explainability. In a step-by-step approach, these guidelines are\\nfurther translated into a framework of concrete recommendations for specifying,\\ndeveloping, evaluating, and deploying technically, clinically and ethically\\ntrustworthy AI solutions into clinical practice.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Enforcing Mutual Consistency of Hard Regions for Semi-supervised Medical Image Segmentation</td>\n      <td>In this paper, we proposed a novel mutual consistency network (MC-Net+) to\\neffectively exploit the unlabeled hard regions for semi-supervised medical\\nimage segmentation. The MC-Net+ model is motivated by the observation that deep\\nmodels trained with limited annotations are prone to output highly uncertain\\nand easily mis-classified predictions in the ambiguous regions (e.g. adhesive\\nedges or thin branches) for the image segmentation task. Leveraging these\\nregion-level challenging samples can make the semi-supervised segmentation\\nmodel training more effective. Therefore, our proposed MC-Net+ model consists\\nof two new designs. First, the model contains one shared encoder and multiple\\nsightly different decoders (i.e. using different up-sampling strategies). The\\nstatistical discrepancy of multiple decoders' outputs is computed to denote the\\nmodel's uncertainty, which indicates the unlabeled hard regions. Second, a new\\nmutual consistency constraint is enforced between one decoder's probability\\noutput and other decoders' soft pseudo labels. In this way, we minimize the\\nmodel's uncertainty during training and force the model to generate invariant\\nand low-entropy results in such challenging areas of unlabeled data, in order\\nto learn a generalized feature representation. We compared the segmentation\\nresults of the MC-Net+ with five state-of-the-art semi-supervised approaches on\\nthree public medical datasets. Extension experiments with two common\\nsemi-supervised settings demonstrate the superior performance of our model over\\nother existing methods, which sets a new state of the art for semi-supervised\\nmedical image segmentation.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Parameter Decoupling Strategy for Semi-supervised 3D Left Atrium Segmentation</td>\n      <td>Consistency training has proven to be an advanced semi-supervised framework\\nand achieved promising results in medical image segmentation tasks through\\nenforcing an invariance of the predictions over different views of the inputs.\\nHowever, with the iterative updating of model parameters, the models would tend\\nto reach a coupled state and eventually lose the ability to exploit unlabeled\\ndata. To address the issue, we present a novel semi-supervised segmentation\\nmodel based on parameter decoupling strategy to encourage consistent\\npredictions from diverse views. Specifically, we first adopt a two-branch\\nnetwork to simultaneously produce predictions for each image. During the\\ntraining process, we decouple the two prediction branch parameters by quadratic\\ncosine distance to construct different views in latent space. Based on this,\\nthe feature extractor is constrained to encourage the consistency of\\nprobability maps generated by classifiers under diversified features. In the\\noverall training process, the parameters of feature extractor and classifiers\\nare updated alternately by consistency regularization operation and decoupling\\noperation to gradually improve the generalization performance of the model. Our\\nmethod has achieved a competitive result over the state-of-the-art\\nsemi-supervised methods on the Atrial Segmentation Challenge dataset,\\ndemonstrating the effectiveness of our framework. Code is available at\\nhttps://github.com/BX0903/PDC.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Background-Foreground Segmentation for Interior Sensing in Automotive Industry</td>\n      <td>To ensure safety in automated driving, the correct perception of the\\nsituation inside the car is as important as its environment. Thus, seat\\noccupancy detection and classification of detected instances play an important\\nrole in interior sensing. By the knowledge of the seat occupancy status, it is\\npossible to, e.g., automate the airbag deployment control. Furthermore, the\\npresence of a driver, which is necessary for partially automated driving cars\\nat the automation levels two to four can be verified. In this work, we compare\\ndifferent statistical methods from the field of image segmentation to approach\\nthe problem of background-foreground segmentation in camera based interior\\nsensing. In the recent years, several methods based on different techniques\\nhave been developed and applied to images or videos from different\\napplications. The peculiarity of the given scenarios of interior sensing is,\\nthat the foreground instances and the background both contain static as well as\\ndynamic elements. In data considered in this work, even the camera position is\\nnot completely fixed. We review and benchmark three different methods ranging,\\ni.e., Gaussian Mixture Models (GMM), Morphological Snakes and a deep neural\\nnetwork, namely a Mask R-CNN. In particular, the limitations of the classical\\nmethods, GMM and Morphological Snakes, for interior sensing are shown.\\nFurthermore, it turns, that it is possible to overcome these limitations by\\ndeep learning, e.g.\\ using a Mask R-CNN. Although only a small amount of ground\\ntruth data was available for training, we enabled the Mask R-CNN to produce\\nhigh quality background-foreground masks via transfer learning. Moreover, we\\ndemonstrate that certain augmentation as well as pre- and post-processing\\nmethods further enhance the performance of the investigated methods.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Text embedding with TF-IDF vectorizer\ntfidf_vec = TfidfVectorizer()\n\ntfidf_vec.fit(data[\"titles\"])\n\ndata_tfidf = tfidf_vec.transform(data[\"titles\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-10T03:29:52.330689Z","iopub.execute_input":"2024-06-10T03:29:52.3311Z","iopub.status.idle":"2024-06-10T03:29:54.23593Z","shell.execute_reply.started":"2024-06-10T03:29:52.331058Z","shell.execute_reply":"2024-06-10T03:29:54.234615Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def find_most_similar_paper(query, data, tfidf_vectorizer, data_tfidf):\n    # Vectorize the query\n    query_vec = tfidf_vectorizer.transform([query])\n    \n    # Compute cosine similarity between the query and all documents\n    cosine_similarities = cosine_similarity(query_vec, data_tfidf).flatten()\n    \n    print(\"Query vector:\\n\", query_vec.toarray())\n    print(\"Data vectors:\\n\", data_tfidf.toarray())\n    print(\"Cosine similarities:\\n\", cosine_similarities)\n    \n    # Find the index of the most similar document\n    most_similar_idx = np.argmax(cosine_similarities)\n    \n    # Return the most similar document and similarity score\n    return data.iloc[most_similar_idx], cosine_similarities[most_similar_idx]","metadata":{"execution":{"iopub.status.busy":"2024-06-10T03:29:54.238008Z","iopub.execute_input":"2024-06-10T03:29:54.238465Z","iopub.status.idle":"2024-06-10T03:29:54.247738Z","shell.execute_reply.started":"2024-06-10T03:29:54.238425Z","shell.execute_reply":"2024-06-10T03:29:54.24655Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"query = \"i want a paper about ML and cyber security\"\nmost_similar_paper, similarity_score = find_most_similar_paper(query, data, tfidf_vec, data_tfidf)\n\nprint(f\"Most similar paper: {most_similar_paper}\")\nprint(f\"Similarity score: {similarity_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T03:34:20.047289Z","iopub.execute_input":"2024-06-10T03:34:20.047871Z","iopub.status.idle":"2024-06-10T03:34:22.519467Z","shell.execute_reply.started":"2024-06-10T03:34:20.04783Z","shell.execute_reply":"2024-06-10T03:34:22.518166Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Query vector:\n [[0. 0. 0. ... 0. 0. 0.]]\nData vectors:\n [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\nCosine similarities:\n [0.         0.0113729  0.         ... 0.01264806 0.         0.        ]\nMost similar paper: titles                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Semisupervised Adversarial Neural Networks for Cyber Security Transfer Learning\nsummaries    On the path to establishing a global cybersecurity framework where each\\nenterprise shares information about malicious behavior, an important question\\narises. How can a machine learning representation characterizing a cyber attack\\non one network be used to detect similar attacks on other enterprise networks\\nif each networks has wildly different distributions of benign and malicious\\ntraffic? We address this issue by comparing the results of naively transferring\\na model across network domains and using CORrelation ALignment, to our novel\\nadversarial Siamese neural network. Our proposed model learns attack\\nrepresentations that are more invariant to each network's particularities via\\nan adversarial approach. It uses a simple ranking loss that prioritizes the\\nlabeling of the most egregious malicious events correctly over average\\naccuracy. This is appropriate for driving an alert triage workflow wherein an\\nanalyst only has time to inspect the top few events ranked highest by the\\nmodel. In terms of accuracy, the other approaches fail completely to detect any\\nmalicious events when models were trained on one dataset are evaluated on\\nanother for the first 100 events. While, the method presented here retrieves\\nsizable proportions of malicious events, at the expense of some training\\ninstabilities due in adversarial modeling. We evaluate these approaches using 2\\npublicly available networking datasets, and suggest areas for future research.\nName: 9609, dtype: object\nSimilarity score: 0.3654098740228027\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}